# -*- coding: utf-8 -*-
"""Credit Card Fraud Detction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfzdTD4d60p8Znw-cLFCww21ixrOrq66

Importing the Dependencies|
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Loading the dataset to a Padas DataFrame
credit_card_data = pd.read_csv("/content/creditcard.csv")

# First 5 rows of dataset
credit_card_data.head()

credit_card_data.tail()

# Dataset Information
credit_card_data.info()

# Checking the no. of missing values in each column
credit_card_data.isnull().sum()

# Distribution of ligit transaction and fraudlent Transactions
credit_card_data['Class'].value_counts()

"""This dataset is highly inbalanced

0-----> Normal Transaction

1-----> Fraudlent Transaction
"""

# Seprating the data for analysis
legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]

print(legit.shape, fraud.shape)

# statistical measure of the data
legit.Amount.describe()

fraud.Amount.describe()

# Comparing the values for both transactions

credit_card_data.groupby('Class').mean()

"""Under-Sampling

Build a sample dataset containg similar distribution of normal transaction and Fraudlent Transactions

Number of Fraudlent Transaction --> 492
"""

legit_sample = legit.sample(n=492) #  map random 492 values of normal transaction

"""Concatinating two Data-Frames"""

new_dataset = pd.concat([legit_sample,fraud], axis=0) # axis 0 means that value is added row wise

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

"""Splitting the data into Features and Targets"""

X = new_dataset.drop(columns='Class', axis=1)
Y = new_dataset['Class']

print(X)

print(Y)

"""Split the data into Training data & Testing Data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Model Training

Logistic Regression
"""

model = LogisticRegression()

# Training the Logistic Regression Model with Training Data
model.fit(X_train, Y_train)

"""Model Evaluation

Accuracy Score
"""

# Accuracy on training Data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print('Accuracy on Training data : ', training_data_accuracy)

# Accuracy on Testing Data
X_test_prediction = model.predict(X_test)
testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy on Testing data : ', testing_data_accuracy)

